# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zs1WFuEH8D0ccruBTGbXKpmcOHDktcUX
"""

import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

print(x_train.shape) # (60000, 28, 28)
print(y_train.shape) # (60000, )

import matplotlib.pyplot as plt

print("Y[0] : ",  y_train[0])
plt.imshow(x_train[0], cmap=plt.cm.gray_r, interpolation = "nearest")



#CNN
tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, padding='same', activation='relu')
tf.keras.layers.MaxPooling2D(pool_size=(2, 2))
tf.keras.layers.Flatten()
tf.keras.layers.Dropout(rate=0.5)

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# 각종 파라메터의 영향을 보기 위해 랜덤값 고정
tf.random.set_seed(1234)

# Normalizing data
x_train, x_test = x_train / 255.0, x_test / 255.0

# (60000, 28, 28) => (60000, 28, 28, 1)로 reshape
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# One-hot 인코딩
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, input_shape=(28,28,1), padding='same', activation='relu'),
    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2)),

    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, padding='valid', activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size=(2,2)),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=10, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(lr=0.001), metrics=['accuracy'])
model.summary()

model.fit(x_train, y_train, batch_size=100, epochs=5, validation_data=(x_test, y_test))

result = model.evaluate(x_test, y_test)
print("최종 예측 성공률(%): ", result[1]*100)

def find_misclassified(model, x_data, y_true):
    y_pred = model.predict(x_data)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_true, axis=1)
    misclassified_indices = np.where(y_pred_classes != y_true_classes)[0]
    return misclassified_indices

# 잘못 분류된 데이터 인덱스 찾기
misclassified_indices = find_misclassified(model, x_test, y_test)
print("개수:", len(misclassified_indices))
print("잘못 분류된 인덱스:", misclassified_indices)

num_columns = 8  # 한 행에 표시할 이미지의 개수
num_rows = (num_misclassified - 1) // num_columns + 1  # 행의 개수 계산

plt.figure(figsize=(15, 15))

for i, idx in enumerate(misclassified_indices):
    plt.subplot(num_rows, num_columns, i + 1)
    plt.imshow(x_test[idx], cmap='gray')
    true_label = np.argmax(y_test[idx])
    predicted_label = np.argmax(model.predict(x_test[idx][np.newaxis, ...]))
    plt.title(f"True: {true_label}, Predicted: {predicted_label}")
    plt.axis('off')

plt.tight_layout()
plt.show()



# Logistic Regression

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

# Step 1: 데이터 준비
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# 데이터를 평탄화
x_train_flat = x_train.reshape(-1, 28 * 28)
x_test_flat = x_test.reshape(-1, 28 * 28)

# Step 2: 모델 정의
model = Sequential([
    Dense(10, activation='softmax', input_shape=(784,)) # 입력 형태를 명시적으로 지정
])

# Step 3: 손실 함수 정의
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()

# Step 4: 옵티마이저 설정
optimizer = tf.keras.optimizers.Adam()

# Step 5: 모델 훈련
model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])
model.fit(x_train_flat, y_train, batch_size=100, epochs=10, validation_data=(x_test_flat, y_test))

import numpy as np

# 모델의 예측 결과를 가져옵니다.
y_pred_prob = model.predict(x_test_flat)
y_pred = np.argmax(y_pred_prob, axis=1)

# 오분류된 인덱스를 찾습니다.
misclassified_indices = np.where(y_pred != y_test)[0]

# 오분류된 샘플의 개수를 출력합니다.
print("오분류 개수:", len(misclassified_indices))
print("잘못 분류된 인덱스:", misclassified_indices)



# ANN

import torch
from torch import nn
import numpy
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

train_data = datasets.MNIST(root='../data', train=True, download=True, transform=transforms.ToTensor())
test_data = datasets.MNIST(root='../data', train=False, download=True, transform=transforms.ToTensor())

plt.imshow(train_data[0][0].reshape(28, 28), cmap='gist_yarg')
plt.show()

batch_size = 100

train_batch = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
test_batch = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)

class ModelANN(nn.Module):
    def __init__(self, size_in, size_out, size_hidden):
        super().__init__()
        self.hidden1 = nn.Linear(size_in, size_hidden[0])
        self.hidden2 = nn.Linear(size_hidden[0], size_hidden[1])
        self.out = nn.Linear(size_hidden[1], size_out)

    def forward(self, x):
        h1 = nn.functional.relu(self.hidden1(x))
        h2 = nn.functional.relu(self.hidden2(h1))
        y = nn.functional.log_softmax(self.out(h2), dim=1)
        return y

model = ModelANN(784, 10, [200, 100])

learning_rate = 0.0001
epochs = 10
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    train_result = 0
    test_result = 0
    for index, (x_train, y_train) in enumerate(train_batch):
        index += 1
        train_output = model(x_train.view(100, -1))
        answer = torch.max(train_output.data, 1)[1]
        batch_result = (answer == y_train).sum()
        train_result += batch_result
        train_loss = criterion(train_output, y_train)
        if index % 100 == 0:
            print('Loss of {}.{} : {} ({}%)'.format(epoch, index,
                                                    train_loss.item(), train_result.item() / index))
        train_loss.backward()
        optimizer.step()
    model.eval()
    with torch.no_grad():
        for index, (x_test, y_test) in enumerate(test_batch):
            test_output = model(x_test.view(100, -1))
            answer = torch.max(test_output.data, 1)[1]
            test_result += (answer == y_test).sum()
        loss = criterion(test_output, y_test)
        print('test {} : {}%'.format(epoch, test_result.item() / 100))

model.eval()
misclassified_indices = []

with torch.no_grad():
    for idx, (x_test, y_test) in enumerate(test_batch):
        test_output = model(x_test.view(100, -1))
        answers = torch.max(test_output, 1)[1]
        misclassified_indices.extend(idx * 100 + i for i, (a, y) in enumerate(zip(answers, y_test)) if a != y)

print("오분류데이터 인덱스:", misclassified_indices)
print(len(misclassified_indices))

model.eval()
misclassified_images = []

with torch.no_grad():
    for x_test, y_test in test_batch:
        test_output = model(x_test.view(100, -1))
        answers = torch.max(test_output, 1)[1]
        misclassified_indices = (answers != y_test).nonzero()[:, 0]
        misclassified_images.extend([(x_test[i], answers[i], y_test[i]) for i in misclassified_indices])

# Visualize misclassified images
plt.figure(figsize=(20, 20))
columns = 10
rows = 53  # 522개의 이미지를 10x53 그리드로 표시

for i, (image, predicted, actual) in enumerate(misclassified_images):
    if i == columns * rows:
        break
    plt.subplot(rows, columns, i + 1)
    plt.imshow(image.view(28, 28), cmap='gray')
    plt.title(f'Predicted: {predicted}, Actual: {actual}')
    plt.axis('off')

plt.tight_layout()
plt.show()



# DNN (손글씨 MNIST)

import pandas as pd
from tensorflow.keras.datasets import mnist
import numpy as np

(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

import matplotlib.pyplot as plt
import random

for i in range(1,4,1):
    for j in range(1,4,1):
        plt.subplot(i,4,j)
        plt.imshow(x_train[random.randint(0,60000)],cmap="gray")
    plt.show()

x_train_new = x_train.reshape(-1, 784)
x_test_new = x_test.reshape(-1, 784)

x_train_ = x_train_new / 255.0
x_test_ = x_test_new / 255.0

from keras.utils import to_categorical

y_train_new = to_categorical(y_train)
y_test_new = to_categorical(y_test)

y_train_new

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.metrics import accuracy_score

model = Sequential([
    Dense(512, input_dim=784, activation='relu'),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train_, y_train_new, validation_data=(x_test_, y_test_new), epochs=10)

y_pred = model.predict(x_test_)
y_pred

import numpy as np

t = []

for i in range(len(y_pred)):
    t.append(np.argmax(y_pred[i]))

accuracy_score(y_test, t)

misclassified_indices = []

for i in range(len(y_pred)):
    if t[i] != y_test[i]:
        misclassified_indices.append(i)

print("오분류된 데이터의 인덱스:", misclassified_indices)

plt.figure(figsize=(20, 20))
plt.suptitle('Misclassified Examples')

num_misclassified = len(misclassified_images)
num_columns = 15  # 한 행에 표시할 이미지의 개수
num_rows = (num_misclassified - 1) // num_columns + 1  # 행의 개수 계산

for i in range(num_misclassified):
    plt.subplot(num_rows, num_columns, i + 1)
    plt.imshow(misclassified_images[i], cmap='gray', interpolation='nearest')  # interpolation 옵션을 추가하여 이미지를 크게 표시
    plt.title(f'Predicted: {misclassified_predictions[i]}\nActual: {misclassified_labels[i]}')
    plt.axis('off')

plt.tight_layout(h_pad=0.5, w_pad=0.5)  # h_pad와 w_pad 옵션을 사용하여 수직 및 수평 간격 조절
plt.show()



# 에러 리스트
#CNN
_t = """175  340  449  625  646  689  947 1014 1039 1224 1232 1247 1260 1319
 1500 1527 1901 2070 2118 2130 2135 2293 2387 2414 2462 2597 2654 2720
 2896 2927 2939 3023 3225 3384 3422 3520 3558 3559 3662 3727 3767 3808
 3838 3985 4007 4027 4284 4425 4571 4740 4761 4807 4823 4837 4876 4966
 5654 5937 5955 6576 6597 6599 6625 6783 6847 7441 7514 8246 8408 9015
 9642 9729 9768 9770"""
cnn_error = [int(_) for _ in _t.split()]
print(len(cnn_error))

#DNN
dnn_error = [115, 247, 321, 340, 381, 445, 495, 582, 619, 684, 720, 726, 740, 882, 900, 947, 951, 956, 1014, 1039, 1112, 1156, 1194, 1224, 1226, 1242, 1247, 1260, 1310, 1319, 1328, 1378, 1393, 1395, 1494, 1530, 1549, 1554, 1609, 1611, 1621, 1730, 1878, 1901, 1930, 1941, 1987, 2018, 2035, 2043, 2053, 2093, 2105, 2109, 2125, 2130, 2135, 2182, 2272, 2293, 2369, 2387, 2422, 2426, 2488, 2573, 2582, 2597, 2607, 2648, 2654, 2720, 2810, 2877, 2921, 2927, 2939, 2953, 3005, 3023, 3030, 3073, 3422, 3451, 3475, 3503, 3520, 3558, 3702, 3776, 3780, 3808, 3811, 3817, 3821, 3838, 3893, 3906, 3976, 3985, 4027, 4176, 4194, 4224, 4248, 4271, 4317, 4369, 4497, 4500, 4504, 4571, 4615, 4761, 4823, 4880, 4966, 5086, 5331, 5457, 5642, 5654, 5676, 5734, 5887, 5936, 5937, 5955, 5973, 5982, 6009, 6011, 6023, 6059, 6065, 6101, 6428, 6555, 6560, 6572, 6574, 6576, 6597, 6641, 6651, 6755, 6783, 6847, 6971, 7434, 7472, 7909, 8062, 8094, 8246, 8255, 8277, 8316, 8318, 8325, 8376, 8509, 8520, 8522, 8527, 9009, 9015, 9024, 9280, 9587, 9634, 9664, 9669, 9679, 9700, 9729, 9764, 9770, 9792, 9808, 9839, 9856, 9858, 9944]
print("DNN 오분류된 데이터 개수:", len(dnn_error))

# ANN
ann_error = [8, 124, 149, 151, 217, 233, 241, 247, 259, 290, 313, 320, 321, 324, 340, 352, 358, 362, 381, 386, 403, 412, 435, 445, 448, 449, 478, 479, 495, 502, 507, 530, 543, 551, 565, 578, 582, 591, 628, 659, 684, 691, 707, 717, 720, 740, 839, 844, 874, 882, 890, 924, 938, 947, 950, 951, 956, 965, 982, 999, 1014, 1032, 1039, 1044, 1062, 1068, 1107, 1112, 1114, 1124, 1128, 1166, 1181, 1182, 1192, 1194, 1198, 1200, 1204, 1226, 1228, 1232, 1234, 1242, 1247, 1251, 1260, 1283, 1289, 1299, 1310, 1319, 1326, 1337, 1364, 1378, 1393, 1413, 1433, 1444, 1467, 1469, 1500, 1522, 1525, 1527, 1530, 1549, 1553, 1559, 1569, 1581, 1587, 1609, 1621, 1626, 1634, 1640, 1641, 1681, 1717, 1721, 1737, 1751, 1754, 1765, 1774, 1790, 1800, 1828, 1843, 1850, 1857, 1878, 1901, 1917, 1938, 1940, 1941, 1952, 1970, 1982, 2016, 2024, 2035, 2040, 2043, 2044, 2053, 2068, 2070, 2093, 2098, 2099, 2109, 2118, 2129, 2130, 2135, 2174, 2182, 2185, 2186, 2189, 2224, 2266, 2272, 2293, 2299, 2329, 2369, 2371, 2387, 2393, 2395, 2406, 2414, 2422, 2423, 2425, 2433, 2488, 2514, 2526, 2548, 2556, 2598, 2607, 2617, 2631, 2648, 2654, 2670, 2713, 2730, 2745, 2760, 2771, 2863, 2866, 2877, 2896, 2921, 2925, 2927, 2945, 2953, 2970, 2995, 3005, 3060, 3073, 3110, 3117, 3129, 3130, 3136, 3157, 3167, 3189, 3206, 3225, 3240, 3254, 3269, 3284, 3289, 3329, 3330, 3376, 3490, 3503, 3520, 3549, 3550, 3558, 3559, 3565, 3567, 3573, 3597, 3629, 3634, 3662, 3664, 3674, 3702, 3716, 3718, 3751, 3757, 3767, 3776, 3780, 3806, 3808, 3811, 3817, 3821, 3833, 3834, 3836, 3838, 3846, 3848, 3853, 3855, 3862, 3869, 3871, 3893, 3902, 3906, 3926, 3941, 3943, 3946, 3951, 3962, 3968, 3976, 3985, 3986, 3995, 4000, 4017, 4027, 4063, 4065, 4075, 4078, 4093, 4131, 4140, 4152, 4154, 4163, 4176, 4199, 4201, 4205, 4211, 4212, 4224, 4248, 4286, 4289, 4300, 4301, 4306, 4315, 4327, 4344, 4355, 4369, 4374, 4380, 4400, 4425, 4433, 4435, 4437, 4449, 4477, 4497, 4498, 4521, 4523, 4536, 4571, 4575, 4578, 4601, 4615, 4635, 4639, 4640, 4731, 4735, 4751, 4785, 4807, 4814, 4823, 4833, 4837, 4863, 4874, 4876, 4879, 4880, 4886, 4890, 4910, 4915, 4950, 4952, 4956, 4966, 4990, 5065, 5067, 5078, 5140, 5165, 5176, 5183, 5209, 5210, 5331, 5457, 5495, 5600, 5601, 5623, 5634, 5642, 5678, 5734, 5749, 5842, 5887, 5888, 5891, 5913, 5922, 5936, 5937, 5955, 5972, 5973, 5985, 6042, 6045, 6046, 6059, 6065, 6071, 6081, 6091, 6157, 6166, 6168, 6172, 6173, 6347, 6370, 6390, 6391, 6392, 6400, 6421, 6425, 6426, 6428, 6505, 6532, 6555, 6568, 6571, 6590, 6597, 6598, 6599, 6603, 6621, 6625, 6632, 6641, 6651, 6744, 6746, 6765, 6769, 6785, 6793, 6847, 6926, 7049, 7121, 7208, 7216, 7220, 7432, 7434, 7451, 7459, 7539, 7797, 7800, 7821, 7858, 7886, 7888, 7899, 7917, 7928, 7945, 8020, 8062, 8081, 8094, 8183, 8246, 8272, 8277, 8294, 8311, 8325, 8326, 8339, 8406, 8408, 8410, 8426, 8520, 8522, 8863, 9009, 9015, 9016, 9019, 9022, 9024, 9036, 9280, 9316, 9587, 9624, 9634, 9642, 9643, 9662, 9679, 9698, 9700, 9729, 9732, 9744, 9745, 9749, 9768, 9770, 9779, 9808, 9839, 9858, 9879, 9890, 9892, 9905, 9944, 9959, 9975, 9982]

print(len(ann_error))

# CNN & DNN
cnn_error_set = set(cnn_error)
dnn_error_set = set(dnn_error)

common_errors = cnn_error_set.intersection(dnn_error_set)

print("공통된 오분류된 데이터 개수:", len(common_errors))
print("공통된 오분류된 데이터 인덱스:", common_errors)

# CNN.csv
import pandas as pd

list_to_dict = []

for index in misclassified_indices:
    list_to_dict.append({"모델": "CNN", "데이터 번호": index, "정답": np.argmax(y_test[index]), "오답": np.argmax(model.predict(x_test[index:index+1]))})

# Convert the list of dictionaries to a DataFrame
df = pd.DataFrame(list_to_dict)

# Save the DataFrame to a CSV file
df.to_csv("CNN.csv", encoding="utf-8-sig", index=False)

# DNN.csv
y_true_classes = y_test
y_pred_classes = t

list_to_dict = []

for index in misclassified_indices:
    list_to_dict.append({"모델":"DNN", "데이터 번호":index, "정답":y_true_classes[index], "오답":y_pred_classes[index]})

df = pd.DataFrame(list_to_dict)
df.to_csv("DNN.csv", encoding="utf-8-sig")

# ANN.csv
list_to_dict = []

for index in misclassified_indices:
    list_to_dict.append({"모델":"ANN", "데이터 번호":index, "정답":y_true_classes[index], "오답":y_pred_classes[index]})

df = pd.DataFrame(list_to_dict)
df.to_csv("ANN.csv", encoding="utf-8-sig")



"""공통된 오분류 34개데이터"""

from google.colab import drive
import pandas as pd

drive.mount('/content/drive')

ann_csv_path = '/content/drive/MyDrive/ANN.csv'
cnn_csv_path = '/content/drive/MyDrive/CNN.csv'
dnn_csv_path = '/content/drive/MyDrive/DNN.csv'

res_ann = pd.read_csv(ann_csv_path)
res_ann.columns = ["no", "model", "i", "true", "pred"]
res_ann = res_ann.iloc[:, 1:]

res_cnn = pd.read_csv(cnn_csv_path)
res_cnn.columns = ["model", "i", "true", "pred"]

res_dnn = pd.read_csv(dnn_csv_path)
res_dnn.columns = ["no", "model", "i", "true", "pred"]
res_dnn = res_dnn.iloc[:, 1:]

res = pd.concat([res_ann, res_cnn, res_dnn])

print(res.head(3))

set_ann = set(res.loc[res["model"] == "ANN", "i"])
set_cnn = set(res.loc[res["model"] == "CNN", "i"])
set_dnn = set(res.loc[res["model"] == "DNN", "i"])

set_all = set_ann & set_cnn & set_dnn

print(len(set_all))

res_all = res.loc[res["i"].isin(set_all), :].copy()

res_all_pivot = res_all.pivot(index=["i", "true"], columns="model", values="pred").reset_index()
res_all_pivot.to_csv("res_all_pivot.csv", index=False, encoding="utf-8-sig")

import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))
columns = 6
rows = 6

for i, index in enumerate(sorted(list(set_all))):
  if i == columns * rows:
    break

  plt.subplot(rows, columns, i + 1)
  plt.imshow(x_test[index], cmap="gray")
  plt.title(f"no. {index}\nTruth: {y_test[index]}", fontdict={"fontsize":8})
  plt.axis("off")

plt.tight_layout()
plt.show()

list_all_indices = sorted(list(set_all))

print(list_all_indices)

res_ann = pd.read_csv(ann_csv_path)
res_ann.columns = ["no", "model", "i", "true", "pred"]
res_ann = res_ann.loc[res_ann["model"] == "ANN"]

indices_to_check = [340, 947, 1014, 1039, 1224, 1247,
                    1260, 1319, 1901, 2130, 2135, 2293,
                    2387, 2654, 2927, 3520, 3558, 3808,
                    3838, 3985, 4027, 4571, 4761, 4823,
                    4966, 5937, 5955, 6597, 6783, 6847,
                    8246, 9015, 9729, 9770]

plt.figure(figsize=(15, 10))

# 데이터 인덱스 리스트를 순회하면서 이미지와 예측 결과를 시각화
for i, index in enumerate(indices_to_check, 1):
    # ANN 모델의 예측 값 가져오기
    ann_prediction = res_ann.loc[res_ann["i"] == index, "pred"].values[0]
    true_label = res_ann.loc[res_ann["i"] == index, "true"].values[0]

    # 이미지 플로팅
    plt.subplot(4, 9, i)
    plt.imshow(x_test[index], cmap="gray")
    plt.title(f"Predicted: {ann_prediction}\nActual: {true_label}", fontsize=10)
    plt.axis("off")

# 그래프 제목 설정
plt.suptitle("ANN Model Predictions for Selected Indices", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])  # 그래프 간격 조정
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# CNN 모델의 예측 결과가 담긴 CSV 파일 읽기
res_cnn = pd.read_csv(cnn_csv_path)
res_cnn.columns = ["model", "i", "true", "pred"]
res_cnn = res_cnn.loc[res_cnn["model"] == "CNN"]

# 시각화할 데이터 인덱스 리스트
indices_to_check = [340, 947, 1014, 1039, 1224, 1247, 1260, 1319, 1901, 2130,
                    2135, 2293, 2387, 2654, 2927, 3520, 3558, 3808, 3838,
                    3985, 4027, 4571, 4761, 4823, 4966, 5937, 5955, 6597,
                    6783, 6847, 8246, 9015, 9729, 9770]

# 그래프 설정
plt.figure(figsize=(15, 10))

# 데이터 인덱스 리스트를 순회하면서 이미지와 예측 결과를 시각화
for i, index in enumerate(indices_to_check, 1):
    # CNN 모델의 예측 값 가져오기
    cnn_prediction = res_cnn.loc[res_cnn["i"] == index, "pred"].values[0]
    true_label = res_cnn.loc[res_cnn["i"] == index, "true"].values[0]

    # 이미지 플로팅
    plt.subplot(4, 9, i)
    plt.imshow(x_test[index], cmap="gray")
    plt.title(f"Predicted: {cnn_prediction}\nActual: {true_label}", fontsize=10)
    plt.axis("off")

# 그래프 제목 설정
plt.suptitle("CNN Model Predictions for Selected Indices", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])  # 그래프 간격 조정
plt.show()

# DNN 모델의 예측 결과가 담긴 CSV 파일 읽기
res_dnn = pd.read_csv(dnn_csv_path)
res_dnn.columns = ["no", "model", "i", "true", "pred"]
res_dnn = res_dnn.loc[res_dnn["model"] == "DNN"]

# 시각화할 데이터 인덱스 리스트
indices_to_check = [340, 947, 1014, 1039, 1224, 1247, 1260, 1319, 1901, 2130,
                    2135, 2293, 2387, 2654, 2927, 3520, 3558, 3808, 3838,
                    3985, 4027, 4571, 4761, 4823, 4966, 5937, 5955, 6597,
                    6783, 6847, 8246, 9015, 9729, 9770]

# 그래프 설정
plt.figure(figsize=(15, 10))

# 데이터 인덱스 리스트를 순회하면서 이미지와 예측 결과를 시각화
for i, index in enumerate(indices_to_check, 1):
    # DNN 모델의 예측 값 가져오기
    dnn_prediction = res_dnn.loc[res_dnn["i"] == index, "pred"].values[0]
    true_label = res_dnn.loc[res_dnn["i"] == index, "true"].values[0]

    # 이미지 플로팅
    plt.subplot(4, 9, i)
    plt.imshow(x_test[index], cmap="gray")
    plt.title(f"Predicted: {dnn_prediction}\nActual: {true_label}", fontsize=10)
    plt.axis("off")

# 그래프 제목 설정
plt.suptitle("DNN Model Predictions for Selected Indices", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])  # 그래프 간격 조정
plt.show()



